
\chapter{Les évolutions du business modèle des Data Centres}
\label{chap-1}

Ce chapitre a pour but de définir un data centre afin de pouvoir analyser ses problématiques, enjeux et solutions possibles, en vue de comprendre son état actuel et ses limites par rapport aux nouveaux besoins et défis business. Les éléments les plus importants de la conception et de l'architecture du data centre seront présentés ainsi que les difficultés qui l'ont amené faire à évoluer son modèle de livraison vers l'approche Cloud Computing\index{Cloud Computing}.

\section{Data centres et leurs objectifs}

Un data centre (aussi nommé \og ferme de serveurs \fg{}) est un répertoire centralisé pour le stockage\index{Stockage}, le management et la distribution de données et d'informations. Typiquement, un data centre\index{Data Centre} est une installation utilisée pour loger des systèmes informatiques et ses composants associés, tels que systèmes de télécommunication et stockage. 

Les data centres traditionnels hébergent historiquement de nombreuses applications relativement petites ou moyennes, chacune s'exécutant dans une infrastructure matérielle dédiée qui est isolée et protégée des autres systèmes dans la même installation. Ces data centres accueillent du matériel et du logiciel pour multiples unités organisationnelles ou même diverses entreprises. Différents systèmes informatiques au sein d'un tel data centre ont souvent très peu d'éléments en commun en termes de matériel, logiciel ou infrastructure de maintenance, et en général ne communiquent pas entre eux. 


Les tendances de l'informatique vers une approche côté serveur et l'explosion en popularité des services sur internet ont changé ce scénario. Des infrastructures data centre entières ont été dédiées à un seul acteur pour faire fonctionner ses services offerts. Dans ce cadre, un data centre appartient à une seule organisation et utilise des matériels et plateformes logicielles relativement homogènes qui partagent une couche commune de systèmes de management. Ces data centres dédiés exécutent un nombre réduit d'applications (ou services internet) beaucoup plus importants en taille; l'infrastructure commune de management permet alors une meilleure flexibilité de déploiement. 

Ces infrastructures\index{Infrastructure} sont montées pour gérer la taille des applications\index{Application} déployées et la haute disponibilité exigée pour ces services, visant en général 99,99\% de durée de fonctionnement (une heure au maximum de temps d'arrêt par an). Il est difficile d'atteindre un fonctionnement libre des failles dans un regroupement de systèmes matériel et cela devient encore plus complexe avec le grand nombre de serveurs impliqués.

\par
Les infrastructures de ces data centres doivent être dimensionnées précisément  en fonction de la charge des applications supportées. Par conséquent, des nouvelles approches ont été proposées pour la construction et l'opération de ces systèmes qui doivent être conçus pour tolérer un nombre important de failles avec très peu ou aucun impact sur la performance et disponibilité des services offerts. \cite{understandingCloudWhatDC}  \cite{datacenterAsComputerIntro}

\section{Organisation d'un data centre et difficultés}

%A data center is generally organized in rows of ‘‘racks” where each rack contains modular assets such as servers, switches, storage ‘‘bricks”, or specialized appliances
Un data centre est en général organisé en lignes de racks où chaque rack\index{Rack} contient des dispositifs modulaires tels que serveurs, switches, briques de stockages ou instruments spécialisés. %Trois principaux éléments d'infrastructure constituent les data centres : le stockage, le réseau et l'approvisionnement énergétique.
Des composants essentiels de l'infrastructure, branchés aux racks des data centres d'entreprises tels que compute, stockage et réseau, sont la base sur laquelle les applications business sont construites. Un châssis se présente avec ses propres ventilateurs, source d'alimentation, panier d'interconnexion et module de management. 
Pour réduire l'espace occupé, des serveurs peuvent être compartimentés dans un châssis qui est glissé dans le rack. Un châssis fournit des slots de taille standard où il est possible d'insérer des élément actifs modulaires (aussi connus en tant que \og blades \fg{}). Un seul châssis peut contenir 16 serveurs 1 U; étant donné que les racks supportent 6 châssis, ils ont une capacité théorique de 96 éléments modulaires.


\begin{figure}[h]
\begin{center}
\includegraphics[width=0.7\textwidth]{images/racks} 
\caption{Organisation de racks. \cite{datacenterAsComputerIntro}}\label{racks}
\end{center}
\end{figure}

La figure \ref{racks} montre l'organisation des racks dans un data centre. Un serveur occupant 1 U du rack est visualisé à gauche. Au centre on peut voir un rack et à droite un cluster de racks avec un swtich/routeur\index{Routeur} de niveau cluster. En général un ensemble de serveurs 1U sont montés dans un rack et inter-connectés à un commutateur Ethernet local. Ces switches\index{Commutateur!switch} au niveau des racks, qui peuvent utiliser des liens de 1 à 10 Gbps, ont un nombre de connexions montantes vers un ou plus switches de niveau cluster (data centre).

Le stockage dans les data centres peut être proposé de diverses manières. Souvent le stockage de haute performance est logé dans des \og  tours de stockage \fg{} qui permettent un accès distant transparent au stockage, indépendamment du nombre et des types des dispositifs de stockage physiques installés. Le stockage peut également être fourni dans une \og  brique de stockage \fg{} plus petite, localisée dans le rack ou slot de châssis ainsi que directement intégrée aux serveurs. Dans tous les cas, un accès réseau efficace au stockage est crucial.

Le problème le plus important dans cette structure est l'éventuelle insuffisance de bande passante. En général, les connexions montantes sont conçues pour supporter un certain taux de demandes excédentaires puisque la fourniture d'une bande passante entière n'est pas toujours possible. Par exemple, pour 20 serveurs à 1Gbps, chacun doit partager un lien Ethernet montant unique de 10Gps à un taux de demande excédentaire de 2. Cette situation peut être problématique si la charge réseau non locale monte considérablement. Comme le stockage est traditionnellement fourni dans une tour séparée, tout le trafic\index{Trafic} de stockage traverse le lien montant dans le réseau stockage. Par exemple, l'archivage d'un gros volume peut consommer une importante bande passante. À mesure que les data centres augmentent en taille, une architecture réseau plus extensible\index{Extensible} devient essentielle.

La consommation d'énergie est également une des préoccupations de la conception des data centres, car les coûts\index{Coûts} liés sont devenus une part importante de la totalité des coûts pour cette classe de systèmes. Actuellement les CPUs ne sont plus le seul élément cible d'amélioration de l'efficacité\index{Efficacité} énergétique\index{Énergie!énergétique}, car ils ne dominent plus la majorité de la consommation. Des problématiques de ventilation et surconsommation d'énergie sont des facteurs de plus en plus critiques dans la conception de data centres.\cite{datacenterAsComputerIntro} \cite{dataCenterEvolution}

\section{Virtualisation et partage de ressources}

Le besoin d'augmenter l'efficacité dans l'utilisation des ressources a conduit à une conception d'infrastructures avec partage de ressources et virtualisation. La virtualisation\index{Virtualisation} fait référence à l'abstraction des ressources logiques de leurs couches physiques pour améliorer l'agilité, la flexibilité et la réduction des coûts et ainsi privilégier le business. La virtualisation permet de consolider un ensemble de composants d'infrastructures sous-utilisés en un nombre de dispositifs plus petits et mieux utilisés, contribuant à l'économie des coûts.

La virtualisation de serveurs est une méthode pour abstraire le système d'exploitation de la plateforme matérielle. Cela permet aux multiples systèmes d'exploitation ou multiples instances du même système d'exploitation de coexister dans un ou plusieurs processeurs. L'image \ref{virtinfra} illustre le partage de ressources\index{Ressources} par l'intermédiaire de la virtualisation.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.98\textwidth]{images/shared_infa_virt} 
\caption{Modèle d'infrastructure à ressources partagées. \cite{journeySDDC}}\label{virtinfra}
\end{center}
\end{figure}

Un hyperviseur\index{Hyperviseur} ou moniteur de machines virtuelles\index{VM!machines virtuelles} est inséré entre le système d'exploitation et le matériel pour réaliser la séparation entre le logique et le physique. Les instances de systèmes d'exploitation lancées sont appelées invités, ou systèmes d'exploitation invités. L'hyperviseur fournit l'émulation matérielle aux systèmes invités et gèrent l'allocation de ressources matérielles.  Les principaux hyperviseurs disponibles sur marché aujourd'hui sont : VMware\index{VMware} ESXi, KVM basé sur Linux et supporté par Red Hat, Citrix XEN et Microsoft Hyper-V. 

%Ce modèle apporte des avantages en termes de comment les ressources sont efficacement utilisées avec des charges applicatives idéales.
Ce modèle apporte des avantages pour l'efficacité\index{Efficacité} dans l'utilisation de ressources avec des charges applicatives idéales.
 Cependant, quand une application commence à consommer plus de ressources que l'estimé, il peut arriver des scénarios où les systèmes d'exploitation invités n'ont pas assez de ressources, impactant ainsi la qualité du service business offert. 

Cette approche a apporté une maitrise globale de management, monitoring et outillage. Elle a aussi mis en évidence que le composant \og compute\index{Compute} \fg{} de l'infrastructure améliore clairement l'utilisation et automatisation des ressources serveurs. Cette amélioration a été possible grâce à la programmation du contrôle de ressources fournies aux instances invitées. Toutefois, le développement de nouvelles solutions pour gérer la charge dynamique de certaines application faisait toujours défaut. \cite{journeySDDC} \cite{ibmPlanningVirtCCchap2}

%This model has its advantages in terms of how resources are efficiently utilized in ideal applica- tion workloads. However, when one or more appli- cation workloads begin to consume more resourc- es than expected, scenarios could arise where several guest operating systems are short of compute resources, thereby impacting business application service level agreements.
%While this approach brought holistic capacity management, monitoring and tools capabilities, it also provided evidence that infrastructure compute and server resources were truly ben- efiting from improved resource utilization and automation. This was brought about, to a certain extent, by programmatically controlling the resources provided to guest instances. However, new thinking about solutions was still needed to meet the challenges of dynamic workloads of run- the-business applications and compute-intensive enterprise applications.



\section{Le besoin d'un modèle plus dynamique}


Traditionnellement, les data centres\index{Data Centre} d'entreprises sont conçus pour durer pour toujours et atteindre les objectives déterminés de l'économie. Cela veut dire que les éléments sous-jacents sont dimensionnés\index{Dimensionnement} et construits pour supporter le pic de charge\index{Charge} projeté en termes de performance, disponibilité et sécurité. Quand la croissance volumétrique projetée ne correspond pas à la réalité, cette méthode de dimensionnement peut conduire à une situation de sous-dimensionnement ou sur-dimensionnement. Ce qui apporte un effet négatif pour les investissements et les effort de réduction de coûts\index{Coûts}.

En général, pour atteindre une meilleure disponibilité, les infrastructures sont amenées à une sous-utilisation des ressources. Comme la charge des applications varient continuellement dans les applications sur internet, il reste deux choix : soit sous-dimensionner la provision et perdre des clients ou alors sur-dimensionner et gaspiller les ressources. 

Dans tous les cas, un plan détaillé de capacité est fait pour spécifier une série d'investissements importants en matériel et logiciel, dont la charge maximale est déterminée. L'image suivante illustre cette planification et les situations de problèmes de dimensionnement.


\begin{figure}[h]
\begin{center}
\includegraphics[width=0.98\textwidth]{images/fixed_capacity_load_prediction} 
\caption{Capacité fixe de ressources vs charge prévisionnelle. \cite{awsScaling}}
\end{center}
\end{figure}

Face à cette problématique, un nouveau mode de livraison\index{Delivery Model!Mode de livraison} a été proposé pour aborder les défis du traitement des demandes pour la variation dynamique des charges applicatives. Avec la nouvelle tendance du Cloud Computing et l'\gls{iaas}\index{IaaS}, la conception de \glspl{cluster}\index{Cluster} hautement disponibles et des solutions extensibles peut être architecturée avec des requis non-fonctionnels comme base. 
%With the emergence of the cloud, the new age “mantra” and infrastructure as a service (IaaS) as a delivery model (as illustrated in Figure 3), the challenges of processing demands from dynamic workloads is being addressed. Designing high- availability clusters and scalable solutions can be architected based on nonfunctional requirements.

Avec sa nature extensible, le modèle de livraison cloud permet aux ressources\index{Ressources} d'être étendues\index{Extensible!étendues} et réduites  dynamiquement en fonction de la consommation. Une couche logicielle d'abstraction, implémentée par les hyperviseurs, virtualise le traitement des ressources physiques,  permettant ainsi au processeur\index{Compute!processeurs}, à la mémoire et aux disques durs de s'accommoder aux variations des demandes. \cite{journeySDDC} \cite{awsScaling}

%One of the biggest technical challenges of running an online business is how well they are able to handle the scalability requirements.  The Load traffic pattern keeps varying for online businesses and accordingly they will have to scale and maintain the acceptable performance levels.  Since the Traffic patterns are fluctuating in online business, they either tend to under provision and loose customers (or) over provision and waste hardware + costs. This problem is well illustrated in the below diagrams.
%Business usually makes detailed capacity planning and large upfront investment in their hardware and software. This HW/SW’s are usually provisioned with fixed capacity.

%Traditionally, enter-prise data centers are designed to last forever and meet visible business objectives, meaning that their underlying components are sized and built for a projected workload. They are also sized and built using application volumetric modeling and nonfunctional requirements such as perfor-mance, availability, scalability and security.

%The infrastructure is designed and provisioned considering the specific volumetric for support- ing the business applications and considering the peak load transaction in jobs per second, avail- ability and scalability requirements. When volu- metric and projected growth do not manifest as envisaged, this method of sizing infrastructure compute and storage could lead to either under- sizing or oversizing the footprint. Often, having such islands of infrastructure compute and storage leads to underutilization of resources. This has a cascading effect on investment and the effort expended toward energy consumption, management overheads, software licenses and data center costs.


%The shortcomings of this model led many enter- prises to the next wave of infrastructure design — utilizing shared infrastructure services and virtualized compute to increase efficiency in resource utilization and ensure that infrastruc- ture is designed and fit for the purpose, and not over-engineered.

%Virtualization refers to the abstraction of logical resources away from their underlying physical resources to improve agility and flexibility, reduce costs, and thus enhance business value. Virtualization allows a set of underutilized physical infrastructure components to be consolidated into a smaller number of better utilized devices, contributing to significant cost savings.

%Server virtualization is a method of abstracting the operating system from the hardware platform. This allows multiple operating systems or multiple instances of the same operating system to coexist on one or more processors. A hypervisor or virtual machine monitor (VMM) is inserted between the operating system and the hardware to achieve this separation. These operating systems are called “guests” or “guest OSs.” The hypervisor provides hardware emulation to the guest operating systems. It also manages allocation of hardware resources between operating systems.

%According to a recent Gartner study, the leading challenges facing today’s data centers are intrinsic to many of the aforementioned business drivers and their associated IT solutions. Top challenges cited include: 
%• Keeping up with data growth 
%• Maintaining system performance and scalability
%• Mitigating network congestion and connectivity issues
%• Minimizing power, cooling and space costs
%• Effectively managing the data center and its infrastructure
%Furthermore, according to a 2011 survey of the Data Center Users’ Group (DCUG), the leading infrastructure challenges included data center availability, high heat densities, energy efficiency and maintaining adequate power densities (see Figure 1). Each of these challenges resonates closely with the leading data center challenges faced by IT professionals.


%\section{Virtualisation}



%Integrated infrastructure solutions are specifically designed to provide advantages compared to a conventional physical infrastructure because they are: 
%•	 Efficient in power usage, space utilization and IT employee productivity
%•	 Economical in initial cost by making use of existing infrastructure and not requiring expensive room upgrades
%•	 Interoperable through simplified design and implementation of systems and components 
%•	 Controllable through planning, monitoring and management over the changing IT environment



%\section{Tendances des meilleures pratiques}


%Integrated infrastructure solutions are specifically designed to provide advantages compared to a conventional physical infrastructure because they are: 
%•	 Efficient in power usage, space utilization and IT employee productivity
%•	 Economical in initial cost by making use of existing infrastructure and not requiring expensive room upgrades
%•	 Interoperable through simplified design and implementation of systems and components 
%•	 Controllable through planning, monitoring and management over the changing IT environment
%\section{Architecture}

%\chapter{Cloud Computing}

% Un regard sur le nouveau \og business model \fg{} apporté par le Cloud Computing, les bénéfices de son adoption et les enjeux pour les infrastructures qui doivent répondre à ce nouveau paradigme, est l'objet de ce chapitre. Il sera démontré pour quelles raisons il nécessaires de faire évoluer les infrastructures actuelles vers le Cloud et pourquoi il n'est pas encore largement adopté.

\section{Cloud Computing}
En termes très simples, le Cloud Computing\index{Cloud Computing} peut être défini comme un nouveau modèle de consommation et livraison\index{Delivery Model} de ressources de \gls{ti} et de services métiers, et est principalement caractérisé par :
\begin{itemize}
\item Libre service à la demande;
\item Service réseau très accessible;
\item Location indépendante de services en commun;
\item Extensibilité et approvisionnement rapides;
\item Paiement à la consommation.
\end{itemize}
%In very simple terms, cloud computing is a new consumption and delivery model for information technology (IT) and business services and is characterized by:
% • On-demand self-service
% • Ubiquitous network access
% • Location-independent resource pooling
% • Rapid elasticity and provisioning
% • Pay-per-use

\par
Les avancements importants dans la virtualisation\index{Virtualisation}, réseau\index{Réseau}, approvisionnement et architectures multi-tenantes\index{Multi-Tenant} ont permis de faire évoluer radicalement les infrastructures de data centres. Le plus grand impact du Cloud Computing\index{Cloud Computing} vient de l'instauration de nouveaux modèles de consommation et de livraison de services qui supportent l'innovation\index{Innovation} du business\index{Business}.

%Cloud has evolved from on demand and grid computing, while building on significant advances in virtualization, networking, provisioning, and multitenant architectures. As with any new technology, the exciting impact comes from enabling new service consumption and delivery models that support business model innovation.


L'évolution des data centres a permis de rendre service à une plus grande variété de besoins dans le monde du travail, ce qui implique la prise en compte de plusieurs facteurs lors de la conception face à différents objectifs. Le Cloud Computing est donc né en tant que nouveau paradigme pour les architectures data centre.

%As we have seen, data centers have grown to serve a wide range of business needs, and there are many factors to consider when designing a solution that meets different objectives. Within the past several years, a powerful new paradigm has emerged that has important implications for data center architectures and how they meet these varied objectives. This is the paradigm of cloud computing.

Le Cloud Computing livre dynamiquement des services sur des réseaux\index{Réseau} à partir d'un ensemble abstrait de ressources. Ces ressources se retrouvent quelque part dans le \og nuage \fg{} (symbole qui fait allusion à la représentation d'internet dans les topologies réseau) disponibles immédiatement à la demande. Les types de ressources ainsi que leur localisation sont transparents aux utilisateurs finaux. Ces utilisateurs se soucient principalement que leurs applications, données et contenus soient sécurisés et disponibles, avec un niveau de qualité spécifié.

%Cloud computing delivers services dynamically over networks from an abstracted set of resources. The resources are somewhere in the cloud and available on demand. The types of resources and their location are transparent to end users. End users primarily care that their applications, data and content are secure and available, with a desired level of quality.

Du point de vue de l'infrastructure, le Cloud Computing fait des fortes demandes aux ressources\index{Ressources} mutualisées dans une variété de technologies (de compute, de stockage, de réseau) pour leur allocation dynamique. Tout ceci dans un environnement automatisé, orchestré et logiquement diversifié, en conciliant une variété d'applications. L'orchestration\index{Orchestration} permet de mutualiser les ressources\index{Ressources} à travers multiples data centres pour une réponse dynamique aux besoins clients. 


La virtualisation de serveurs a représenté un premier et important pas pour la viabilité de l'approche Cloud Computing. Toutefois, les autres deux éléments de base de l'infrastructure data centre doivent accompagner ces changements pour autoriser un accès complet aux services offerts par le Cloud. Plus spécifiquement la couche d'abstraction, assurée par les hyperviseurs\index{Hyperviseur} qui ont permis la séparation des systèmes logiques des serveurs physiques dans le cas de la virtualisation de serveurs\index{Compute!Virtualisation des serveurs}, doit être également appliquée aux matériels réseaux\index{Virtualisation du Réseau} et de stockage\index{Virtualisation du Stockage}. Cela permettra la définition d'un data centre entièrement piloté par du logiciel\index{Software-Defined Data Center!Data centre piloté par logiciel} qui gère\index{Gestion} les ressources physiques, en les activant selon la charge applicative\index{Charge} spécifiée à assurer.

%\pagebreak

 L'image suivante illustre une vue conceptuelle d'un data centre basé sur ces trois éléments avec des couches d'abstraction permettant de sécuriser, orchestrer et livrer ses ressources aux consommateurs.

\begin{figure}[h]
\begin{center}

%\begin{wrapfigure}{r}{0.6\textwidth}
\includegraphics[width=0.85\textwidth]{images/CloudRefArchi} 
\caption{Vue conceptuelle d'un data centre. \cite{ciscoCCDCStrategyArchiSolutions}} \label{cloud_conceptual_view}
%\end{wrapfigure} 

\end{center}
\end{figure}

L'abstraction\index{Abstraction} de ces trois composants matériels est essentielle pour achever le mode de livraison Cloud au sein des data centres. L'adoption de la virtualisation des serveurs a déjà atteint son grand public ; en 2009 un sondage avait révélé que 77\% des répondants déployaient au moins un système virtualisé dans leur data centre \cite{x86ServersVirtualization}. On observe qu'actuellement beaucoup des travaux en recherche et développement se déroulent pour acquérir un niveau équivalent de maturité pour les dispositifs réseau et stockage. 

L'abstraction du stockage signifie la capacité à mutualiser les dispositifs physiques de stockage pour pouvoir les utiliser en tant que volumes de stockage logiques. C'est qui caractérise la virtualisation du stockage ou le \gls{sds}.\index{Virtualisation du stockage!\gls{sds}} Pour l'aspect stockage, il est reconnu que des solutions \gls{sds} se trouvent disponibles sur le marché, telles que EMC ViPR, HP\index{HP} StoreVirtual, IBM SmartCloud Virtual Storage Center entre autres.

De manière similaire, il se développe pour les réseaux une technologie fournissant une couche d'abstraction pour divers dispositifs réseau afin de permettre l'isolation logique et l'indépendance du matériel. Il se trouve que \gls{sdn}\index{SDN} est une des approches proposées pour traiter la problématique de l'abstraction réseau et fait donc l'objet de cette étude. Le chapitre suivant démontrera en quoi les réseaux traditionnels ne sont pas adaptés aux exigences du Cloud Computing et analysera des exemples sur divers problèmes rencontrés. L'approche SDN et ses apports seront détaillés par la suite.
\cite{ibmPlanningVirtCCchap1}  \cite{cloudReadyJuniperReferenceDef} \cite{journeySDDC} \cite{ciscoCCDCStrategyArchiSolutions}

