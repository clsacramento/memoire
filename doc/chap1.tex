
\chapter{Les évolutions stratégiques des Data Centres}
\label{chap-1}

Ce chapitre a pour but de définir un data centre et d'en analyser les problématiques, enjeux et solutions possibles, en vue de comprendre sa situation actuelle ainsi que ses limites par rapport aux nouveaux besoins et défis business. Les éléments les plus importants de la conception et de l'architecture du data centre seront présentés ainsi que les difficultés qui ont amené à faire évoluer le mode de livraison\index{Mode de livraison} de services informatiques vers une approche Cloud Computing\index{Cloud Computing}.

\section{Data centres et leurs objectifs}

Un data centre (aussi nommé \og ferme de serveurs \fg{}) est un répertoire centralisé pour le stockage\index{Stockage}, le management et la distribution de données et d'informations. Typiquement, un data centre est une installation physique utilisée pour loger des systèmes informatiques et ses composants associés, tels que systèmes de télécommunication et stockage. 

Les data centres traditionnels hébergent historiquement de nombreuses applications relativement peu sollicitées, chacune s'exécutant dans une infrastructure matérielle dédiée qui est isolée et protégée des autres systèmes dans la même installation physique. Ces data centres accueillent du matériel et du logiciel pour multiples unités organisationnelles ou même diverses entreprises. Différents systèmes informatiques au sein d'un tel data centre ont souvent très peu d'éléments en commun en termes de matériel, logiciel ou infrastructure de maintenance, et en général ne communiquent pas entre eux. 


Les tendances de l'informatique vers une approche "serveur" et l'explosion en popularité des services sur internet ont changé ce scénario. Des infrastructures data centre entières ont été dédiées à un seul acteur pour faire fonctionner ses services offerts. Dans ce cadre, un data centre appartient à une seule organisation et utilise des matériels et plateformes logicielles relativement homogènes qui partagent une couche commune de systèmes de management. Ces data centres dédiés exécutent un nombre réduit d'applications (ou services internet) beaucoup plus sollicitées; l'infrastructure commune de management permet alors une meilleure flexibilité de déploiement. 

Ces infrastructures\index{Infrastructure} sont montées pour absorber la croissance des applications déployées et la haute disponibilité exigée pour ces services, visant en général 99,99\% (une heure au maximum de temps d'arrêt par an). Il est difficile d'atteindre un fonctionnement libre des failles dans un regroupement de systèmes matériel et cela devient encore plus complexe avec le grand nombre de serveurs impliqués.

\par
Les infrastructures de ces data centres doivent être dimensionnées\index{Dimensionnement} précisément  en fonction de la charge\index{Charge} des applications supportées. Par conséquent, de nouvelles approches ont été proposées pour la construction et l'opération de ces systèmes qui doivent être conçus pour tolérer un nombre important de failles avec très peu ou aucun impact sur la performance et disponibilité des services offerts. \cite{understandingCloudWhatDC}  \cite{datacenterAsComputerIntro}

\section{Organisation d'un data centre et difficultés}

%A data center is generally organized in rows of ‘‘racks” where each rack contains modular assets such as servers, switches, storage ‘‘bricks”, or specialized appliances
Un data centre est en général organisé en rangées de racks où chaque rack contient des dispositifs modulaires tels que serveurs, switches\index{Switch}, baies de stockages\index{Stockage} ou équipements spécialisés. %Trois principaux éléments d'infrastructure constituent les data centres : le stockage, le réseau et l'approvisionnement énergétique.
Les composants essentiels de l'infrastructure, branchés aux racks des data centres d'entreprises, sont classés en tant que compute\index{Compute}, stockage et réseau et représentent la base sur laquelle les applications business sont construites. 

Un châssis se présente avec ses propres ventilateurs, source d'alimentation, fond de panier et module de gestion\index{Gestion}. 
Pour réduire l'espace occupé, des serveurs peuvent être compartimentés dans un châssis qui est glissé dans le rack. Un châssis fournit des slots %taille standard 
où il est possible d'insérer des élément actifs modulaires (aussi connus en tant que \og blades \fg{}). Par exemple, un seul châssis peut contenir 16 serveurs 1 U; étant donné que les racks supportent 6 châssis, ils ont donc une capacité théorique de 96 éléments modulaires.


\begin{figure}[h]
\begin{center}
\includegraphics[width=0.7\textwidth]{images/racks} 
\caption{Organisation de racks. \cite{datacenterAsComputerIntro}}\label{racks}
\end{center}
\end{figure}

La figure \ref{racks} montre l'organisation des racks dans un data centre. Un serveur occupant 1 U du rack est visualisé à gauche. Au centre on peut voir un rack et à droite un cluster de racks avec un swtich/routeur\index{Routeur} de niveau cluster. En général un ensemble de serveurs 1U est monté dans un rack et inter-connecté à un commutateur Ethernet local. Ces switches\index{Switch} au niveau des racks, qui peuvent utiliser des liens de 1 à 10 Gbps, ont un nombre de connexions montantes vers un ou plus switches de niveau cluster (data centre).

Le stockage\index{Stockage} dans les data centres peut être proposé de diverses manières. Souvent le stockage de haute performance est logé dans des baies de stockage qui permettent un accès distant transparent aux données, indépendamment du nombre et des types des dispositifs de stockage physiques installés. Le stockage peut également être fourni dans une \og  brique de stockage \fg{} plus petite, localisée dans le rack ou slot de châssis ainsi que directement intégrée aux serveurs. Dans tous les cas, un accès réseau efficace au stockage est crucial.

Le problème le plus important dans cette structure est l'éventuelle insuffisance de bande passante. En général, les connexions montantes sont conçues pour supporter un certain taux de demandes excédentaires puisque la fourniture d'une bande passante entière n'est pas toujours possible. Par exemple, pour 20 serveurs à 1Gbps, chacun doit partager un lien Ethernet montant unique de 10Gps à un taux de demande excédentaire de 2. Cette situation peut être problématique si la charge réseau non locale au rack monte considérablement. Comme le stockage est traditionnellement fourni dans une baie séparée, tout le trafic\index{Trafic} de stockage traverse le lien montant dans le réseau stockage. Par exemple, l'archivage d'un gros volume peut consommer une importante bande passante. À mesure que les data centres augmentent en taille, une architecture réseau plus extensible\index{Scalabilité} devient essentielle.

La consommation d'énergie\index{Énergie} et les coûts\index{Coûts} liés sont devenus également une des préoccupations de la conception des data centres, car ils représentent une part importante de la totalité des dépenses. Actuellement les CPUs ne sont plus le seul élément cible d'amélioration de l'efficacité\index{Efficacité} énergétique\index{Énergie}, car ils ne dominent plus la majorité de la consommation. Des problématiques de refroidissement et consommation d'énergie sont des facteurs de plus en plus critiques dans la conception de data centres.\cite{datacenterAsComputerIntro} \cite{dataCenterEvolution}

\section{Virtualisation et partage de ressources}

Le besoin d'augmenter l'efficacité dans l'utilisation des ressources\index{Ressources} a conduit à une conception d'infrastructures avec partage et virtualisation des composants. La virtualisation\index{Virtualisation} fait référence à l'abstraction des ressources logiques de leurs couches physiques pour améliorer l'agilité\index{Agilité}, la flexibilité et la réduction des coûts\index{Coûts} et ainsi privilégier les activités du business. La virtualisation permet de consolider un ensemble de composants d'infrastructures sous-utilisés en un nombre de dispositifs plus petits et mieux utilisés, contribuant à l'économie des coûts et à l'efficacité de l'utilisation des composants.

La virtualisation de serveurs est une méthode pour abstraire le système d'exploitation de la plateforme matérielle. Cela permet aux multiples systèmes d'exploitation ou multiples instances du même système d'exploitation de coexister dans un ou plusieurs clusters de processeurs. L'image \ref{virtinfra} illustre le partage de ressources\index{Ressources} par l'intermédiaire de la virtualisation.\\

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\textwidth]{images/shared_infa_virt_T} 
\caption{Modèle d'infrastructure à ressources partagées. \cite{journeySDDC}}\label{virtinfra}
\end{center}
\end{figure}

Un hyperviseur\index{Hyperviseur} est inséré entre le système d'exploitation et le matériel pour réaliser la séparation entre le logique et le physique. Les instances de systèmes d'exploitation lancées sont appelées invités, ou systèmes d'exploitation invités. Selon la technologie utilisée, l'hyperviseur\index{Virtualisation} peut fournir l'émulation matérielle aux systèmes invités et gère\index{Gestion} l'allocation de ressources\index{Ressources} matérielles.  Les principaux hyperviseurs disponibles sur le marché aujourd'hui sont : VMware ESXi, KVM basé sur Linux et supporté par Red Hat, Citrix XEN et Microsoft Hyper-V. 

%Ce modèle apporte des avantages en termes de comment les ressources sont efficacement utilisées avec des charges applicatives idéales.
Ce modèle apporte des avantages pour l'efficacité\index{Efficacité} dans l'utilisation de ressources avec des charges applicatives idéales.
 Cependant, quand une application commence à consommer plus de ressources\index{Ressources} que l'estimé, il peut arriver des scénarios où les systèmes d'exploitation invités n'ont pas assez de ressources, impactant ainsi la qualité du service dispensé. 

Cette approche a apporté une maîtrise globale de gestion\index{Gestion}, supervision et outillage. Elle a aussi mis en évidence que le composant \og \gls{compute}\index{Compute} \fg{} de l'infrastructure améliore nettement l'utilisation et l'automatisation d'allocation des ressources serveurs. Cette amélioration a été possible grâce à la programmation du contrôle de ressources fournies aux instances invitées. Toutefois, le développement de nouvelles solutions pour gérer la charge dynamique de certaines applications faisait toujours défaut. \cite{journeySDDC} \cite{ibmPlanningVirtCCchap2}

%This model has its advantages in terms of how resources are efficiently utilized in ideal applica- tion workloads. However, when one or more appli- cation workloads begin to consume more resourc- es than expected, scenarios could arise where several guest operating systems are short of compute resources, thereby impacting business application service level agreements.
%While this approach brought holistic capacity management, monitoring and tools capabilities, it also provided evidence that infrastructure compute and server resources were truly ben- efiting from improved resource utilization and automation. This was brought about, to a certain extent, by programmatically controlling the resources provided to guest instances. However, new thinking about solutions was still needed to meet the challenges of dynamic workloads of run- the-business applications and compute-intensive enterprise applications.



\section{Le besoin d'un modèle plus dynamique}


Traditionnellement, les data centres d'entreprises sont conçus pour perdurer et atteindre les objectives déterminés. Cela veut dire que les éléments sous-jacents sont dimensionnés\index{Dimensionnement} et construits pour supporter le pic de charge\index{Charge} prévu\index{Planification} en termes de performance, disponibilité et sécurité. Quand la croissance volumétrique escomptée ne correspond pas à la réalité, cette méthode de dimensionnement peut conduire à une situation de sous-dimensionnement ou sur-dimensionnement. Ce qui produit un effet négatif pour les investissements et les efforts de réduction de coûts\index{Coûts}.

En général, pour atteindre une meilleure disponibilité, les infrastructures sont amenées à une sous-utilisation des ressources\index{Ressources}. Comme la charge des applications varient continuellement dans les applications sur internet, il reste deux choix : soit sous-dimensionner la provision des ressources et perdre des clients ou alors sur-dimensionner et gaspiller les ressources. 

Dans tous les cas, un plan\index{Planification} détaillé de capacité est fait pour spécifier une série d'investissements importants en matériel et logiciel, dont la charge maximale est déterminée. L'image suivante illustre cette planification et les situations de problèmes de dimensionnement.\\


\begin{figure}[h]
\begin{center}
\includegraphics[width=0.98\textwidth]{images/fixed_capacity_load_prediction_T} 
\caption{Capacité fixe de ressources vs charge prévisionnelle. \cite{awsScaling}}
\end{center}
\end{figure}

Face à cette problématique, un nouveau mode de livraison\index{Mode de livraison} de service a été proposé pour aborder les défis du traitement des demandes pour la variation dynamique des charges applicatives. Avec la nouvelle tendance du Cloud Computing\index{Cloud Computing} et l'\gls{iaas}, la conception de \glspl{cluster} hautement disponibles et leurs solutions extensibles peuvent être architecturées avec des requis non-fonctionnels comme base. 
%With the emergence of the cloud, the new age “mantra” and infrastructure as a service (IaaS) as a delivery model (as illustrated in Figure 3), the challenges of processing demands from dynamic workloads is being addressed. Designing high- availability clusters and scalable solutions can be architected based on nonfunctional requirements.

Avec sa nature adaptable, le modèle de livraison\index{Mode de livraison} cloud permet aux ressources\index{Ressources} d'être étendues\index{Scalabilité} et réduites  dynamiquement en fonction de la consommation. Une couche logicielle d'abstraction\index{Abstraction}, implémentée par les hyperviseurs\index{Hyperviseur}, virtualise\index{Virtualisation} le traitement des ressources physiques,  permettant ainsi au processeur\index{Compute}, à la mémoire et aux disques durs de s'adapter aux variations des demandes. Le réseau physique est également partagé mais n'a pas d'implémentation permettant l'adaptabilité de ces ressources. \cite{journeySDDC} \cite{awsScaling}

%One of the biggest technical challenges of running an online business is how well they are able to handle the scalability requirements.  The Load traffic pattern keeps varying for online businesses and accordingly they will have to scale and maintain the acceptable performance levels.  Since the Traffic patterns are fluctuating in online business, they either tend to under provision and loose customers (or) over provision and waste hardware + costs. This problem is well illustrated in the below diagrams.
%Business usually makes detailed capacity planning and large upfront investment in their hardware and software. This HW/SW’s are usually provisioned with fixed capacity.

%Traditionally, enter-prise data centers are designed to last forever and meet visible business objectives, meaning that their underlying components are sized and built for a projected workload. They are also sized and built using application volumetric modeling and nonfunctional requirements such as perfor-mance, availability, scalability and security.

%The infrastructure is designed and provisioned considering the specific volumetric for support- ing the business applications and considering the peak load transaction in jobs per second, avail- ability and scalability requirements. When volu- metric and projected growth do not manifest as envisaged, this method of sizing infrastructure compute and storage could lead to either under- sizing or oversizing the footprint. Often, having such islands of infrastructure compute and storage leads to underutilization of resources. This has a cascading effect on investment and the effort expended toward energy consumption, management overheads, software licenses and data center costs.


%The shortcomings of this model led many enter- prises to the next wave of infrastructure design — utilizing shared infrastructure services and virtualized compute to increase efficiency in resource utilization and ensure that infrastruc- ture is designed and fit for the purpose, and not over-engineered.

%Virtualization refers to the abstraction of logical resources away from their underlying physical resources to improve agility and flexibility, reduce costs, and thus enhance business value. Virtualization allows a set of underutilized physical infrastructure components to be consolidated into a smaller number of better utilized devices, contributing to significant cost savings.

%Server virtualization is a method of abstracting the operating system from the hardware platform. This allows multiple operating systems or multiple instances of the same operating system to coexist on one or more processors. A hypervisor or virtual machine monitor (VMM) is inserted between the operating system and the hardware to achieve this separation. These operating systems are called “guests” or “guest OSs.” The hypervisor provides hardware emulation to the guest operating systems. It also manages allocation of hardware resources between operating systems.

%According to a recent Gartner study, the leading challenges facing today’s data centers are intrinsic to many of the aforementioned business drivers and their associated IT solutions. Top challenges cited include: 
%• Keeping up with data growth 
%• Maintaining system performance and scalability
%• Mitigating network congestion and connectivity issues
%• Minimizing power, cooling and space costs
%• Effectively managing the data center and its infrastructure
%Furthermore, according to a 2011 survey of the Data Center Users’ Group (DCUG), the leading infrastructure challenges included data center availability, high heat densities, energy efficiency and maintaining adequate power densities (see Figure 1). Each of these challenges resonates closely with the leading data center challenges faced by IT professionals.


%\section{Virtualisation}



%Integrated infrastructure solutions are specifically designed to provide advantages compared to a conventional physical infrastructure because they are: 
%•	 Efficient in power usage, space utilization and IT employee productivity
%•	 Economical in initial cost by making use of existing infrastructure and not requiring expensive room upgrades
%•	 Interoperable through simplified design and implementation of systems and components 
%•	 Controllable through planning, monitoring and management over the changing IT environment



%\section{Tendances des meilleures pratiques}


%Integrated infrastructure solutions are specifically designed to provide advantages compared to a conventional physical infrastructure because they are: 
%•	 Efficient in power usage, space utilization and IT employee productivity
%•	 Economical in initial cost by making use of existing infrastructure and not requiring expensive room upgrades
%•	 Interoperable through simplified design and implementation of systems and components 
%•	 Controllable through planning, monitoring and management over the changing IT environment
%\section{Architecture}

%\chapter{Cloud Computing}

% Un regard sur le nouveau \og business model \fg{} apporté par le Cloud Computing, les bénéfices de son adoption et les enjeux pour les infrastructures qui doivent répondre à ce nouveau paradigme, est l'objet de ce chapitre. Il sera démontré pour quelles raisons il nécessaires de faire évoluer les infrastructures actuelles vers le Cloud et pourquoi il n'est pas encore largement adopté.

\section{Cloud Computing}
Le Cloud Computing\index{Cloud Computing} peut être défini comme un nouveau modèle de consommation et livraison\index{Mode de livraison} de ressources\index{Ressources} et services de \gls{ti}, et a pour principales caractéristiques :
\begin{itemize}
\item Libre service à la demande;
\item Mobilité d'accès au service réseau ;
\item Location indépendante de services dans un pool de ressources commun;
\item Sécurité des ressources, administration automatisée et réglementation de l'utilisation de données ;
\item Extensibilité et approvisionnement rapides;
\item Paiement à la consommation.
\end{itemize}
%In very simple terms, cloud computing is a new consumption and delivery model for information technology (IT) and business services and is characterized by:
% • On-demand self-service
% • Ubiquitous network access
% • Location-independent resource pooling
% • Rapid elasticity and provisioning
% • Pay-per-use

\par
Les avancées importantes dans les domaines de virtualisation\index{Virtualisation}, réseau, approvisionnement et architectures multi-tenantes\index{Tenants} ont permis de faire évoluer radicalement les infrastructures de data centres. Le plus grand impact du Cloud Computing\index{Cloud Computing} vient de l'instauration de nouveaux modèles de consommation et de livraison de services qui encouragent l'innovation\index{Innovation}.

%Cloud has evolved from on demand and grid computing, while building on significant advances in virtualization, networking, provisioning, and multitenant architectures. As with any new technology, the exciting impact comes from enabling new service consumption and delivery models that support business model innovation.


L'évolution des data centres a permis de satisfaire une plus grande variété de besoins dans le monde du travail, ce qui implique la prise en compte de plusieurs facteurs lors de la conception de l'architecture selon les différents objectifs de chaque entreprise. Le Cloud Computing est donc le produit d'un nouveau paradigme pour les architectures des data centres.

%As we have seen, data centers have grown to serve a wide range of business needs, and there are many factors to consider when designing a solution that meets different objectives. Within the past several years, a powerful new paradigm has emerged that has important implications for data center architectures and how they meet these varied objectives. This is the paradigm of cloud computing.

Le Cloud Computing livre dynamiquement des services sur des réseaux à partir d'un ensemble abstrait de ressources\index{Ressources}. Ces ressources se retrouvent quelque part dans le \og nuage \fg{} \footnote{symbole qui fait allusion à la représentation d'internet dans les topologies réseau} et sont disponibles immédiatement à la demande. Les types de ressources ainsi que leur localisation sont transparents aux utilisateurs finaux. Ces utilisateurs ont pour principale préoccupation que leurs applications, données et contenus soient sécurisés et disponibles, avec un certain niveau de qualité de service.

%Cloud computing delivers services dynamically over networks from an abstracted set of resources. The resources are somewhere in the cloud and available on demand. The types of resources and their location are transparent to end users. End users primarily care that their applications, data and content are secure and available, with a desired level of quality.

Du point de vue de l'infrastructure, le Cloud Computing\index{Cloud Computing} sollicite fortement les ressources\index{Ressources} mutualisées dans une grande variété de technologies (compute\index{Compute}, stockage, réseau) pour leur allocation dynamique. Tout ceci dans un environnement automatisé, orchestré et logiquement diversifié, en conciliant une variété d'applications. L'orchestration permet de mutualiser les ressources\index{Ressources} au travers de multiples data centres pour une réponse dynamique\index{Agilité} aux besoins clients. 


La virtualisation de serveurs a représenté un premier et important pas pour la viabilité de l'approche Cloud Computing. Toutefois, les deux autres éléments de base de l'infrastructure des data centres doivent accompagner ces changements pour permettre un accès complet aux services offerts par le Cloud. Les hyperviseurs\index{Hyperviseur} ont permis la séparation des systèmes logiques des serveurs physiques dans le cas de la virtualisation de serveurs\index{Compute} ; cette abstraction\index{Abstraction} doit être également appliquée aux matériels réseaux\index{Virtualisation du Réseau} et de stockage\index{Virtualisation du Stockage}. Cela permettra la définition d'un data centre entièrement piloté par un logiciel qui gère\index{Gestion} les ressources physiques, en les activant dynamiquement selon la charge applicative\index{Charge}.

%\pagebreak

 L'image suivante illustre une vue conceptuelle d'un data centre basé sur ces trois éléments avec des couches d'abstraction\index{Abstraction} permettant de sécuriser\index{Sécurité}, orchestrer et livrer ses ressources\index{Ressources} au consommateur.\\

\begin{figure}[h]
\begin{center}

%\begin{wrapfigure}{r}{0.6\textwidth}
\includegraphics[width=0.6\textwidth]{images/CloudRefArchi_T} 
\caption{Vue conceptuelle d'un data centre. \cite{ciscoCCDCStrategyArchiSolutions}} \label{cloud_conceptual_view}
%\end{wrapfigure} 

\end{center}
\end{figure}

L'abstraction\index{Abstraction} de ces trois composants matériels est essentielle pour permettre la distribution\index{Mode de livraison} de services Cloud au sein des data centres. L'adoption de la virtualisation des serveurs a déjà atteint son public ; en 2009 un sondage avait révélé que 77\% des entreprises consultées déployaient au moins un système virtualisé dans leur data centre \cite{x86ServersVirtualization}. On observe que beaucoup de travaux se déroulent actuellement en recherche et développement pour acquérir un niveau équivalent de maturité pour les dispositifs réseau et stockage. 

L'abstraction du stockage signifie la capacité à mutualiser les dispositifs physiques de stockage pour pouvoir les utiliser en tant que volumes de stockage logiques. Cela caractérise la virtualisation du stockage ou le \gls{sds}.\index{Virtualisation du Stockage} Pour l'aspect stockage, il est reconnu que des solutions \gls{sds} se trouvent disponibles sur le marché, telles que EMC ViPR, HP StoreVirtual, IBM SmartCloud Virtual Storage Center, Red Hat Storage Server entre autres.

Pour les réseaux, il se développe également une technologie fournissant une couche d'abstraction pour divers dispositifs réseau afin de permettre l'isolation logique et l'indépendance du matériel. Il se trouve que \gls{sdn}\index{SDN} est une des approches proposées pour traiter la problématique de l'abstraction réseau et fait donc l'objet de cette étude. Le chapitre suivant démontrera en quoi les réseaux traditionnels ne sont pas adaptés aux exigences du Cloud Computing\index{Cloud Computing} et analysera des exemples sur divers problèmes rencontrés. L'approche SDN et ses apports seront détaillés en dernière partie. \cite{journeySDDC} \cite{ciscoCCDCStrategyArchiSolutions} \cite{ibmPlanningVirtCCchap1}  \cite{cloudReadyJuniperReferenceDef}

